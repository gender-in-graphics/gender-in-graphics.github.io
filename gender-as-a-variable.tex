\PassOptionsToPackage{table}{xcolor}
\documentclass[sigconf,nonacm,review,balance=false]{acmart}
\setcopyright{none}
\citestyle{acmauthoryear}
\setcitestyle{square}

\setcopyright{none}
\acmConference[Under Review]{Under Review}{Under Review}{Online} \acmYear{2021}

\settopmatter{authorsperrow=4}
\input{common-preamble}



\begin{document}

\title{Gender in the Computer Graphics research literature}

\author{Silvia Sellán}
\affiliation{\institution{University of Toronto}}

\author{Ana Dodik}
\affiliation{\institution{Meta}}

\author{Theodore Kim}
\affiliation{\institution{Yale University}}

\author{Amanda Phillips}
\affiliation{\institution{Georgetown University}}


\begin{abstract}
    We survey the treatment of gender in the Computer Graphics research
    literature and its scientific and real-world consequences. We conclude
    current trends on the use of gender in our research community constitute a
    form of algorithmic bias with harmful effects. We propose ways for
    correcting these trends and pose novel research questions.
\end{abstract}


\maketitle


\section{Introduction}

\textit{We captured three actors: one male and two females...} \textit{We
synthesize a [human motion] dataset for each gender...} \textit{We constraint
the search space into [one of] the male and female spaces...} \textit{We use a
male model whose body shape parameters are that of the average male...}

References to gender can be found all throughout the Computer Graphics
literature. Despite advancements in the understanding of gender in biology (e.g., \cite{fausto2012sex}), in the social sciences (e.g., \cite{butler2003gender}) and even in neighboring
fields (e.g., \cite{keyes2021you}), we observe that the treatment of gender in our discipline
still answers to a traditional understanding of it that excludes transgender and
gender non-conforming people.

In what follows, we argue that our community's current use of gender is
imprecise, contradictory and detrimental to our scientific integrity.
We examine the harmful real-world consequences of our modeling
choices with respect to gender on how gender non-conforming people interact with
our technology in their daily lives. We advocate for reexamining our
treatment of gender and show that this will not only correct worrying trends in
our community, but also open the door to whole new avenues of research.

\section{Survey}

Inspired by the work of \citet{keyes2018misgendering}, we conducted a survey of
all technical papers presented at SIGGRAPH North America and SIGGRAPH Asia since
2015 (see supplemental material). We observed references to gender routinely
throughout, varying in nature from demographic information reported about user
study participants to gender-specific algorithms. Whenever gender is used
explicitly as a variable, it is always as a binary one. Despite its prominence,
gender is never given a precise definition in all the reviewed Computer Graphics
literature, and appears to be used implicitly as a proxy for anything from body
proportions to facial expression to voice inflection in speech.

An analysis of the above reveals worrying trends about the current use of gender
as a variable in Computer Graphics, both scientifically and ethically. As we
mention examples of works that perpetuate these trends, we stress that we do not
associate any malicious intent to any. Rather, we wish to show how seemingly
neutral, well-established practices in our community can lead to us unwittingly
perpetuating forms of algorithmic bias.

\section{Scientific critique}

In our strive towards producing precise, high-quality reproducible research, we
should be careful about using only clearly defined variables of study. However,
our survey shows gender to be widely used yet undefined in our literature.

In doing this, we are effectively asking our readers and fellow researchers to
project their common-knowledge understanding of gender to be able to read and
reproduce our results. As centuries of social science teaches us
(\silvia{citations (Amanda?)}), this understanding can vary heavily from person
to person and culture to culture. Thus, different researchers will interpret and
implement our algorithms differently, impeding the advance of our science.

This use of gender as an undefined variable is even more detrimental when
different understandings of gender are conflated, thereby biasing algorithms
towards grouping certain independent attributes together. To use a very
simplified example, a human parametric model may use \emph{female} to refer to a
group of people who generally are shorter \emph{and} have longer hair, and
\emph{male} to refer to those taller \emph{and} with shorter hair. The use of
this poorly-defined variable means that the statistical distributions of hair
length and height are being artificially linked together, biasing the algorithm
against including shorter humans with short hair, and viceversa.

We found examples of this bias throughout the literature: voice modification
algorithms may conflate voice pitch with culturally-acquired speech inflections
under the umbrella of gender, virtual garment try-on methods can merge a
person's body proportions with their preference in attire, a proposed new
conversational agent might join a person's visual appearance with traits in
their non-verbal communication.

Our field's scientific advancement is damaged further when these biases go
unreported and unstudied, as we found is the case in all our reviewed
literature. If a human parametric model by design cannot replicate a certain
sizeable class of humans (e.g, many transgender people), or if a virtual try-on
algorithm cannot allow a person with certain body proportions visualize
themselves wearing a skirt, these are \emph{scientifically} limited algorithms.
Thus, these limitations should be discussed as such so that they do not
unwittingly permeate through the literature and so that others can work on
eliminating them.

\section{Ethical critique}

As scientific researchers, we must be aware of the effect that our arbitrary
modelling decisions have in the real world as our algorithms are used by
governments and private companies. 

Since many people's gender experiences fall outside the male/female binary, our
research's insistence on it can contribute to frustration (at best) and
discrimination (at worst) when they interact with technology. A researcher's
seemingly inocuous decision to use different search spaces for fitting male and
female body proportions leads to airport body scanners that routinely subject
transgender passangers to humilliation (see \cite{tsa}). A modelling choice to
conflate body proportions with choices in attire ironically excludes precisely
the people with non-normative bodies who are the most in danger in traditional
physical changing rooms (see e.g., \cite{changingroom}). 


These negative effects are compounded even further as our algorithms are being
used to generate synthetic datasets on which to train Machine Learning
algorithms outside of our research area. If we do not examine and properly
report our algorithm's limitations in representing people outside of the gender
binary, these can later be used to train autonomous vehicles to detect
pedestrians (\cite{cars}), medical diagnosing tools (\cite{chen2021synthetic})
and even security threat detection (\cite{dhs}).

Furthermore, as Computer Graphics researchers, we must consider our role in
shaping whose stories get to be told and who gets to seem themselves represented
in the entertainment culture. By conflating different attributes under the
umbrella of gender, we exclude gender non-conforming individuals from every
videogame and movie created using our tool, further invisibilizing
already-invisible and marginalized communities.

It bears mentioning that our research community's entrenchment in the
traditional gender binary is a rare example of Computer Graphics research
lagging behind the needs of our partner industries. \emph{Metahuman}, the latest
photorrealistic character modeller by \citet{metahuman} has no mention of
gender; \citet{googlegender} removed all gender references from its Cloud Vision
API; video games as diverse as \emph{Animal Crossing: New Horizons},
\emph{Cyberpunk 2077} and \emph{Forza Horizon 5} completely decouple attributes
like hairstyle, body proportions, voice pitch and prononouns from one another.

Finally, the current use of gender in the Computer Graphics literature creates a
hostile environment for gender non-conforming members of our research community,
which goes against ACM SIGGRAPH's goal to be \emph{a model of inclusion, equity,
access and diversity for all}: by seeing colleagues and collaborators
consistently exclude us from their own research work, we are (willingly or not)
sent the message that we do not belong in this research community, encouraging
us to look for jobs elsewhere.


\section{Where do we go from here?}

We believe the reasons above to be enough to make us reevaluate the role of
gender in our community's scientific literature.

For example, the reporting of gender among other demographic information in user
study participants and dataset collection subjects answer to a scientifically
positive goal (experimental transparency) as well as an ethical one, to
safeguard against the “male default” that plagues science and has plagued it
since its infancy. However, we found instances in our survey of participants
being reported as of “unknown gender”, which may indicate that their gender is
being assumed post facto by researchers as opposed to self reported, leading to
the potential misidentification and exclusion of gender non-conforming
individuals or of those from certain ethnicities (see e.g.,
\cite{santamaria2018comparison,buolamwini2018gender}). Therefore, we would argue
it is still advisable to include this kind of data, as long as it is self
reported by participants who are given a breadth of gender options not
restricted to the traditional binary ones.

On the other hand, the scientific and ethical harm caused by gender-segregated
algorithms is likely too significant to offset any possible benefits. At the
very least, these choices should be justified and their consequences in terms of
excluding gender non-conforming individuals should be examined and clearly
stated. Eventually, we hope that our field evolves to address these limitations
and move beyond the outdated gender binary. We trust that our fellow researchers
share our scientific excitement in this new frame of reference and the potential
novel research directions it opens; for example:
\begin{itemize}
    \item What is a complete parametric model for the human body that is
    decoupled from gender and accurately represents the diverse bodies of all
    humans, regardless of whether they conform to traditional gender norms?
    \item How can our research inform or contrast more modern understandings of
    gender? Can data-based methods be used to evaluate cultural differences in
    gender presentation?
    \item How can we evaluate our algorithms for bias towards the gender binary?
    What tools are needed to obtain or synthesize data that covers more diverse
    experiences of gender?
\end{itemize}

We acknowledge that our proposed break with tradition may bring with it effort
and difficult conversations, but these are challenges worth facing in the
interest of scientific advancement as well as producing a fairer, more inclusive
future.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references.bib}

\end{document}
